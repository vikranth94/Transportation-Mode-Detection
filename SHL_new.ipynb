{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import required Python modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data and pre-proces data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy files \n",
    "data_path='Extracted_data'\n",
    "data_file = 'Train_data.npz'\n",
    "label_file = 'Train_labels.npy'\n",
    "data = np.load(os.path.join(data_path,data_file))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "accx= data['arr_0']\n",
    "accy= data['arr_1']\n",
    "accz= data['arr_2']\n",
    "gyrox= data['arr_3']\n",
    "gyroy= data['arr_4']\n",
    "gyroz= data['arr_5']\n",
    "magx= data['arr_6']\n",
    "magy= data['arr_7']\n",
    "magz= data['arr_8']\n",
    "laccx= data['arr_9']\n",
    "laccy= data['arr_10']\n",
    "laccz= data['arr_11']\n",
    "grax= data['arr_12']\n",
    "gray= data['arr_13']\n",
    "graz= data['arr_14']\n",
    "oriw= data['arr_15']\n",
    "orix= data['arr_16']\n",
    "oriy= data['arr_17']\n",
    "oriz= data['arr_18']\n",
    "press= data['arr_19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16310, 6000, 10)\n",
      "(16310, 6000)\n"
     ]
    }
   ],
   "source": [
    "X = np.float32(np.dstack((np.float32(data['arr_0']), np.float32(data['arr_1']), np.float32(data['arr_2']),\n",
    "                          np.float32(data['arr_3']), np.float32(data['arr_4']), np.float32(data['arr_5']),\n",
    "                         np.float32(data['arr_6']), np.float32(data['arr_7']), np.float32(data['arr_8']),\n",
    "                         np.float32(data['arr_19']))))\n",
    "Y = np.int8(np.load(os.path.join(data_path,label_file)) - 1)\n",
    "Y = np.expand_dims(Y, axis=2)\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3914400000\n",
      "97860000\n"
     ]
    }
   ],
   "source": [
    "print(X.nbytes)\n",
    "print(Y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strided_app(a, L, S ):  # Window len = L, Stride len/stepsize = S\n",
    "    nrows = ((a.shape[0]-L)//S)+1\n",
    "    n = a.strides[0]\n",
    "    return np.lib.stride_tricks.as_strided(a, shape=(nrows,L,a.shape[1] ), strides=(S*n,n,a.strides[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375130, 500, 10)\n"
     ]
    }
   ],
   "source": [
    "X2 = []\n",
    "window = 500\n",
    "stride = 250\n",
    "n_sensors = X.shape[2] #Number of sensors\n",
    "for i in range (0, X.shape[0]):\n",
    "    X2.append(strided_app(X[i],window,stride))\n",
    "    \n",
    "X2 = np.asarray(X2)\n",
    "X2 = X2.reshape((-1,window,n_sensors))\n",
    "del X\n",
    "print(X2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(375130, 500)\n",
      "(375130,)\n"
     ]
    }
   ],
   "source": [
    "Y2 = []\n",
    "n_sensors = 1 #Number of sensors\n",
    "for i in range (0, Y.shape[0]):\n",
    "    Y2.append(strided_app(Y[i],window,stride))\n",
    "    \n",
    "Y2 = np.asarray(Y2)\n",
    "Y2 = Y2.reshape((-1,window,n_sensors))\n",
    "Y2 = np.squeeze(Y2)\n",
    "del Y\n",
    "Y3 = stats.mode(Y2, axis=1)[0]\n",
    "Y3 = np.squeeze(Y3)\n",
    "\n",
    "print(Y2.shape)\n",
    "print(Y3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, CuDNNLSTM, Dense, Dropout, Flatten, Bidirectional\n",
    "from keras.layers import Input, Concatenate, TimeDistributed\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Permute, Reshape, Flatten\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262591, 500, 10)\n",
      "(37513, 500, 10)\n",
      "(75026, 500, 10)\n",
      "(262591,)\n",
      "(37513,)\n",
      "(75026,)\n"
     ]
    }
   ],
   "source": [
    "z = int(0.7 * Y3.shape[0])\n",
    "z1 = int(0.8 * Y3.shape[0])\n",
    "X_train0 = X2[:z]\n",
    "X_val0 = X2[z:z1]\n",
    "X_test0 = X2[z1:]\n",
    "y_train = Y3[:z]\n",
    "y_val = Y3[z:z1]\n",
    "y_test = Y3[z1:]\n",
    "print(np.shape(X_train0))\n",
    "print(np.shape(X_val0))\n",
    "print(np.shape(X_test0))\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_val))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262591, 500, 10)\n",
      "(262591,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "p = np.random.permutation(y_train.shape[0])\n",
    "y_train = y_train[p]\n",
    "X_train0 = X_train0[p,:,:]\n",
    "print(X_train0.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 8\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _data_reshaping(X_tr, X_va, X_ts, network_type):\n",
    "    _, win_len, dim = X_tr.shape\n",
    "    print(network_type)\n",
    "    if network_type=='CNN' or network_type=='ConvLSTM':\n",
    "        \n",
    "        # make it into (frame_number, dimension, window_size, channel=1) for convNet\n",
    "        X_tr = np.swapaxes(X_tr,1,2)\n",
    "        X_va = np.swapaxes(X_va,1,2)\n",
    "        X_ts = np.swapaxes(X_ts,1,2)\n",
    "\n",
    "        X_tr = np.reshape(X_tr, (-1, dim, win_len, 1))\n",
    "        X_va = np.reshape(X_va, (-1, dim, win_len, 1))\n",
    "        X_ts = np.reshape(X_ts, (-1, dim, win_len, 1))\n",
    "        \n",
    "    if network_type=='MLP':\n",
    "        print('MLP...')\n",
    "        X_tr = np.reshape(X_tr, (-1, dim*win_len))\n",
    "        X_va = np.reshape(X_va, (-1, dim*win_len))\n",
    "        X_ts = np.reshape(X_ts, (-1, dim*win_len))\n",
    "    \n",
    "    return X_tr, X_va, X_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_variant(model, num_feat_map, dim, network_type,p):\n",
    "    print(network_type)\n",
    "    if network_type == 'ConvLSTM':\n",
    "        model.add(Permute((2, 1, 3))) # for swap-dimension\n",
    "        model.add(Reshape((-1,num_feat_map*dim)))\n",
    "        model.add(Bidirectional(CuDNNLSTM(32, return_sequences=False, stateful=False)))\n",
    "        #model.add(LSTM(32, return_sequences=False, stateful=False))\n",
    "        model.add(Dropout(p))\n",
    "    if network_type == 'CNN':\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(32, activation='relu'))\n",
    "        model.add(BatchNormalization()) #added\n",
    "        model.add(Dropout(p))\n",
    "\n",
    "        \n",
    "def model_conv(model, num_feat_map,p,b):\n",
    "    model.add(Conv2D(32, kernel_size=(1, 5),    # Original Kernel size(1,5)\n",
    "                 activation='relu',\n",
    "                 input_shape=(dim, win_len, 1),\n",
    "                 padding='same'))\n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) #added\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Conv2D(64, kernel_size=(1, 3), activation='relu',padding='same'))  # Original Kernel size(1,5)\n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) #added\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Conv2D(num_feat_map, kernel_size=(3, 3), activation='relu',padding='same'))  # Original Kernel size(1,5)\n",
    "    if (b==1):\n",
    "        model.add(BatchNormalization()) #added\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Dropout(p))\n",
    "    \n",
    "def model_LSTM(model,p):\n",
    "    model.add(CuDNNLSTM(num_hidden_lstm, \n",
    "               input_shape=(win_len,dim), \n",
    "               return_sequences=True))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(CuDNNLSTM(num_hidden_lstm, return_sequences=False))\n",
    "    model.add(Dropout(p))\n",
    "\n",
    "def model_MLP(model, num_hidden_mlp,p):\n",
    "    model.add(Dense(num_hidden_mlp, activation='relu', input_shape=(dim*win_len,)))\n",
    "    model.add(Dropout(p))\n",
    "    model.add(Dense(num_hidden_mlp, activation='relu'))\n",
    "    model.add(Dropout(p))\n",
    "    \n",
    "def model_output(model):\n",
    "    model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dcbl(p):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(1, 5),    # Original Kernel size(1,5)\n",
    "                 activation='relu',\n",
    "                 input_shape=(dim, win_len, 1),\n",
    "                 padding='same', name = 'Conv_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_1')) #added\n",
    "    model.add(Dropout(p, name = 'drop_1'))\n",
    "    model.add(Conv2D(128, kernel_size=(1, 5), activation='relu',padding='same', name = 'Conv_2'))  \n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), name = 'max_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_2')) #added\n",
    "    model.add(Dropout(p, name = 'drop_2'))\n",
    "    model.add(Conv2D(256, kernel_size=(1, 3), activation='relu',padding='same', name = 'Conv_3'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), name = 'max_2'))\n",
    "    model.add(BatchNormalization(name = 'batch_3')) #added\n",
    "    model.add(Dropout(p, name = 'drop_3'))\n",
    "    model.add(Conv2D(512, kernel_size=(1, 3), activation='relu',padding='same', name = 'Conv_4')) \n",
    "    model.add(MaxPooling2D(pool_size=(1, 2), name = 'max_3'))\n",
    "    model.add(BatchNormalization(name = 'batch_4')) #added\n",
    "    model.add(Dropout(p, name = 'drop_4'))\n",
    "    model.add(Conv2D(256, kernel_size=(1, 3), activation='relu',padding='same', name = 'Conv_5')) \n",
    "    model.add(BatchNormalization(name = 'batch_5')) #added\n",
    "    model.add(Dropout(p, name = 'drop_5'))\n",
    "    model.add(Conv2D(128, kernel_size=(1, 3), activation='relu',padding='same', name = 'Conv_6'))  \n",
    "    model.add(BatchNormalization(name = 'batch_6')) #added\n",
    "    model.add(Dropout(p, name = 'drop_6'))\n",
    "    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu',padding='same', name = 'Conv_7')) \n",
    "    model.add(BatchNormalization(name = 'batch_7')) #added\n",
    "    model.add(Dropout(p, name = 'drop_7'))\n",
    "    model.add(Permute((2, 1, 3), name = 'per_1')) # for swap-dimension\n",
    "    model.add(Reshape((-1,64*dim), name = 'ren_1'))\n",
    "    model.add(Bidirectional(CuDNNLSTM(32, return_sequences=False, stateful=False, name = 'blstm_1')))\n",
    "    model.add(BatchNormalization(name = 'batch_8'))\n",
    "    model.add(Dropout(p, name = 'drop_8'))\n",
    "    model.add(Dense(256, activation='relu', name = 'dense_1'))\n",
    "    model.add(BatchNormalization(name = 'batch_9'))\n",
    "    model.add(Dense(num_classes, activation='softmax', name = 'output'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MA_CNN(input_shape, p=0.3):\n",
    "    input_acc = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    input_gyr = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    input_mag = Input(name='the_input', shape=input_shape, dtype='float32')\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape,\n",
    "               padding='same', name='Conv_1')(input_data)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_1')(x)\n",
    "    x = BatchNormalization(name='Bn_1')(x)\n",
    "    x = Dropout(p, name='Drop_1')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_2')(x)\n",
    "    x = BatchNormalization(name='Bn_2')(x)\n",
    "    x = Dropout(p, name='Drop_2')(x)\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_3')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_3')(x)\n",
    "    x = BatchNormalization(name='Bn_3')(x)\n",
    "    x = Dropout(p, name='Drop_3')(x),\n",
    "    x = Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_4')(x)\n",
    "    x = BatchNormalization(name='Bn_4')(x)\n",
    "    x = Dropout(p, name='Drop_4')(x)\n",
    "    x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_5')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_5')(x)\n",
    "    x = BatchNormalization(name='Bn_5')(x)\n",
    "    x = Dropout(p, name='Drop_5')(x)\n",
    "    x = Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_6')(x)\n",
    "    x = BatchNormalization(name='Bn_6')(x)\n",
    "    x = Dropout(p, name='Drop_6')(x)\n",
    "    x = Conv2D(16, kernel_size=(3, 3), activation='relu', padding='same', name='Conv_7')(x)\n",
    "    x = BatchNormalization(name='Bn_7')(x)\n",
    "    x = Dropout(p, name='Drop_7')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, activation='relu', name='dense_1')(x)\n",
    "    x = BatchNormalization(name='Bn_8')(x)\n",
    "    x = Dropout(p, name='Drop_8')(x)\n",
    "    #output\n",
    "    d1 = Dense(num_classes, activation='softmax', name='dense_out_1')(x)\n",
    "    d2 = Dense(num_classes, activation='softmax', name='dense_out_2' )(x)\n",
    "    d3 = Dense(num_classes, activation='softmax', name='dense_out_3')(x)\n",
    "    d4 = Dense(num_classes, activation='softmax', name='dense_out_4')(x)\n",
    "    d5 = Dense(num_classes, activation='softmax', name='dense_out_5')(x)\n",
    "    d6 = Dense(num_classes, activation='softmax', name='dense_out_6')(x)\n",
    "    model = Model(input_data, [d1,d2,d3,d4,d5,d6])\n",
    "    return model\n",
    "\n",
    "def encoder(s,input_shape, p=0.5):\n",
    "    input_data = Input(name='input_{}'.format(s), shape=input_shape, dtype='float32')\n",
    "    x = Conv2D(64, kernel_size=(1, 5), activation='relu', input_shape=input_shape,\n",
    "               padding='same', name='Conv_1_{}'.format(s))(input_data)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_1{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_1_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_1_{}'.format(s))(x)\n",
    "    x = Conv2D(128, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_2_{}'.format(s))(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2), name='Max_pool_2{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_2_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_2_{}'.format(s))(x)\n",
    "    x = Conv2D(256, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_3_{}'.format(s))(x)\n",
    "    #x = MaxPooling2D(pool_size=(2, 2), name='Max_pool_3_{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_3_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_3_{}'.format(s))(x)\n",
    "    x = Conv2D(256, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_4_{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_4_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_4_{}'.format(s))(x)\n",
    "    x = Conv2D(128, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_5_{}'.format(s))(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2), name='Max_pool_5_{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_5_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_5_{}'.format(s))(x)\n",
    "    x = Conv2D(64, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_6_{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_6'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_6_{}'.format(s))(x)\n",
    "    x = Conv2D(32, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_7_{}'.format(s))(x)\n",
    "    x = BatchNormalization(name='Bn_7_{}'.format(s))(x)\n",
    "    x = Dropout(p, name='Drop_7_{}'.format(s))(x)\n",
    "#     x = Flatten()(x)\n",
    "#     x = Dense(128, activation='relu', name='dense_1_{}'.format(s))(x)\n",
    "#     x = BatchNormalization(name='Bn_8_{}'.format(s))(x)\n",
    "#     x = Dropout(p, name='Drop_8_{}'.format(s))(x)\n",
    "    model = Model(inputs=input_data, outputs=x, name='Encoder_{}'.format(s))\n",
    "    return model\n",
    "\n",
    "def merger(input_shape, encoder_acc, encoder_gyr, encoder_mag, p=0.5):\n",
    "    input_acc = Input(name='encoded_acc', shape=input_shape, dtype='float32')\n",
    "    input_gyr = Input(name='encoded_gyr', shape=input_shape, dtype='float32')\n",
    "    input_mag = Input(name='encoded_mag', shape=input_shape, dtype='float32')\n",
    "    encode_acc = encoder_acc(input_acc)\n",
    "    encode_gyr = encoder_gyr(input_gyr)\n",
    "    encode_mag = encoder_mag(input_mag)\n",
    "    merged = Concatenate()([encode_acc,  encode_gyr, encode_mag])\n",
    "    merged = Conv2D(128, kernel_size=(1, 3), activation='relu', padding='same', name='Conv_merged')(merged)\n",
    "    out = Permute((2, 1, 3), name = 'per_1')(merged) \n",
    "    out = Reshape((-1,128*3), name = 'ren_1')(out)\n",
    "    out = TimeDistributed(Dense(64, name='dense_IR'), name='Time_dense')(out)\n",
    "    out = BatchNormalization(name = 'batch_7')(out)\n",
    "    out = Bidirectional(CuDNNLSTM(32, return_sequences=False, stateful=False, name = 'blstm_1'))(out)\n",
    "    out = BatchNormalization(name = 'batch_8')(out)\n",
    "    out = Dropout(p, name = 'drop_8')(out)\n",
    "   # out = Flatten()(out)\n",
    "    out = Dense(128, activation='relu', name = 'dense_1')(out)\n",
    "    out = BatchNormalization(name = 'batch_9')(out)\n",
    "    out = Dense(num_classes, activation='softmax', name = 'output')(out)\n",
    "    model = Model(inputs=[input_acc,input_gyr,input_mag], outputs=out, name='Merged')\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "10\n",
      "ConvLSTM\n"
     ]
    }
   ],
   "source": [
    "batch_size = 512\n",
    "num_feat_map = 128\n",
    "num_hidden_mlp = 128\n",
    "num_hidden_lstm = 64\n",
    "num_classes = 8\n",
    "p=0.3 #Dropout\n",
    "b = 1 #BatchNorm\n",
    "\n",
    "#network_type = 'CNN'\n",
    "network_type = 'ConvLSTM'\n",
    "#network_type = 'LSTM'\n",
    "#network_type = 'MLP'\n",
    "_, win_len, dim = X_train0.shape\n",
    "print(win_len)\n",
    "print(dim)\n",
    "\n",
    "X_train, X_val, X_test = _data_reshaping(X_train0, X_val0, X_test0, network_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_acc (InputLayer)       (None, 3, 500, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_1_acc (Conv2D)          (None, 3, 500, 64)        384       \n",
      "_________________________________________________________________\n",
      "Bn_1_acc (BatchNormalization (None, 3, 500, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_1_acc (Dropout)         (None, 3, 500, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_acc (Conv2D)          (None, 3, 500, 128)       24704     \n",
      "_________________________________________________________________\n",
      "Max_pool_2acc (MaxPooling2D) (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_2_acc (BatchNormalization (None, 3, 250, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_2_acc (Dropout)         (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_3_acc (Conv2D)          (None, 3, 250, 256)       98560     \n",
      "_________________________________________________________________\n",
      "Bn_3_acc (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_3_acc (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_4_acc (Conv2D)          (None, 3, 250, 256)       196864    \n",
      "_________________________________________________________________\n",
      "Bn_4_acc (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_4_acc (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_5_acc (Conv2D)          (None, 3, 250, 128)       98432     \n",
      "_________________________________________________________________\n",
      "Max_pool_5_acc (MaxPooling2D (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_5_acc (BatchNormalization (None, 3, 125, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_5_acc (Dropout)         (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_6_acc (Conv2D)          (None, 3, 125, 64)        24640     \n",
      "_________________________________________________________________\n",
      "Bn_6 (BatchNormalization)    (None, 3, 125, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_6_acc (Dropout)         (None, 3, 125, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_7_acc (Conv2D)          (None, 3, 125, 32)        6176      \n",
      "_________________________________________________________________\n",
      "Bn_7_acc (BatchNormalization (None, 3, 125, 32)        128       \n",
      "_________________________________________________________________\n",
      "Drop_7_acc (Dropout)         (None, 3, 125, 32)        0         \n",
      "=================================================================\n",
      "Total params: 453,472\n",
      "Trainable params: 451,616\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_gyr (InputLayer)       (None, 3, 500, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_1_gyr (Conv2D)          (None, 3, 500, 64)        384       \n",
      "_________________________________________________________________\n",
      "Bn_1_gyr (BatchNormalization (None, 3, 500, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_1_gyr (Dropout)         (None, 3, 500, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_gyr (Conv2D)          (None, 3, 500, 128)       24704     \n",
      "_________________________________________________________________\n",
      "Max_pool_2gyr (MaxPooling2D) (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_2_gyr (BatchNormalization (None, 3, 250, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_2_gyr (Dropout)         (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_3_gyr (Conv2D)          (None, 3, 250, 256)       98560     \n",
      "_________________________________________________________________\n",
      "Bn_3_gyr (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_3_gyr (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_4_gyr (Conv2D)          (None, 3, 250, 256)       196864    \n",
      "_________________________________________________________________\n",
      "Bn_4_gyr (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_4_gyr (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_5_gyr (Conv2D)          (None, 3, 250, 128)       98432     \n",
      "_________________________________________________________________\n",
      "Max_pool_5_gyr (MaxPooling2D (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_5_gyr (BatchNormalization (None, 3, 125, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_5_gyr (Dropout)         (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_6_gyr (Conv2D)          (None, 3, 125, 64)        24640     \n",
      "_________________________________________________________________\n",
      "Bn_6 (BatchNormalization)    (None, 3, 125, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_6_gyr (Dropout)         (None, 3, 125, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_7_gyr (Conv2D)          (None, 3, 125, 32)        6176      \n",
      "_________________________________________________________________\n",
      "Bn_7_gyr (BatchNormalization (None, 3, 125, 32)        128       \n",
      "_________________________________________________________________\n",
      "Drop_7_gyr (Dropout)         (None, 3, 125, 32)        0         \n",
      "=================================================================\n",
      "Total params: 453,472\n",
      "Trainable params: 451,616\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "None\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_mag (InputLayer)       (None, 3, 500, 1)         0         \n",
      "_________________________________________________________________\n",
      "Conv_1_mag (Conv2D)          (None, 3, 500, 64)        384       \n",
      "_________________________________________________________________\n",
      "Bn_1_mag (BatchNormalization (None, 3, 500, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_1_mag (Dropout)         (None, 3, 500, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_2_mag (Conv2D)          (None, 3, 500, 128)       24704     \n",
      "_________________________________________________________________\n",
      "Max_pool_2mag (MaxPooling2D) (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_2_mag (BatchNormalization (None, 3, 250, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_2_mag (Dropout)         (None, 3, 250, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_3_mag (Conv2D)          (None, 3, 250, 256)       98560     \n",
      "_________________________________________________________________\n",
      "Bn_3_mag (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_3_mag (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_4_mag (Conv2D)          (None, 3, 250, 256)       196864    \n",
      "_________________________________________________________________\n",
      "Bn_4_mag (BatchNormalization (None, 3, 250, 256)       1024      \n",
      "_________________________________________________________________\n",
      "Drop_4_mag (Dropout)         (None, 3, 250, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_5_mag (Conv2D)          (None, 3, 250, 128)       98432     \n",
      "_________________________________________________________________\n",
      "Max_pool_5_mag (MaxPooling2D (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Bn_5_mag (BatchNormalization (None, 3, 125, 128)       512       \n",
      "_________________________________________________________________\n",
      "Drop_5_mag (Dropout)         (None, 3, 125, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_6_mag (Conv2D)          (None, 3, 125, 64)        24640     \n",
      "_________________________________________________________________\n",
      "Bn_6 (BatchNormalization)    (None, 3, 125, 64)        256       \n",
      "_________________________________________________________________\n",
      "Drop_6_mag (Dropout)         (None, 3, 125, 64)        0         \n",
      "_________________________________________________________________\n",
      "Conv_7_mag (Conv2D)          (None, 3, 125, 32)        6176      \n",
      "_________________________________________________________________\n",
      "Bn_7_mag (BatchNormalization (None, 3, 125, 32)        128       \n",
      "_________________________________________________________________\n",
      "Drop_7_mag (Dropout)         (None, 3, 125, 32)        0         \n",
      "=================================================================\n",
      "Total params: 453,472\n",
      "Trainable params: 451,616\n",
      "Non-trainable params: 1,856\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_shape = (3, win_len, 1)\n",
    "encoder_acc = encoder('acc',input_shape)\n",
    "encoder_gyr = encoder('gyr',input_shape)\n",
    "encoder_mag = encoder('mag',input_shape)\n",
    "print(encoder_acc.summary())\n",
    "print(encoder_gyr.summary())\n",
    "print(encoder_mag.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoded_acc (InputLayer)        (None, 3, 500, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoded_gyr (InputLayer)        (None, 3, 500, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoded_mag (InputLayer)        (None, 3, 500, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_acc (Model)             (None, 3, 125, 32)   453472      encoded_acc[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_gyr (Model)             (None, 3, 125, 32)   453472      encoded_gyr[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Encoder_mag (Model)             (None, 3, 125, 32)   453472      encoded_mag[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 3, 125, 96)   0           Encoder_acc[1][0]                \n",
      "                                                                 Encoder_gyr[1][0]                \n",
      "                                                                 Encoder_mag[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Conv_merged (Conv2D)            (None, 3, 125, 128)  36992       concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "per_1 (Permute)                 (None, 125, 3, 128)  0           Conv_merged[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ren_1 (Reshape)                 (None, 125, 384)     0           per_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Time_dense (TimeDistributed)    (None, 125, 64)      24640       ren_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_7 (BatchNormalization)    (None, 125, 64)      256         Time_dense[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_6 (Bidirectional) (None, 64)           25088       batch_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_8 (BatchNormalization)    (None, 64)           256         bidirectional_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "drop_8 (Dropout)                (None, 64)           0           batch_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          8320        drop_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_9 (BatchNormalization)    (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 8)            1032        batch_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,457,512\n",
      "Trainable params: 1,451,432\n",
      "Non-trainable params: 6,080\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "merged_model = merger(input_shape, encoder_acc, encoder_gyr, encoder_mag)\n",
    "print(merged_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 262591 samples, validate on 37513 samples\n",
      "Epoch 1/150\n",
      "262591/262591 [==============================] - 877s 3ms/step - loss: 0.6907 - acc: 0.7517 - val_loss: 2.4276 - val_acc: 0.4284\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42844, saving model to weights_best_merged.hdf5\n",
      "Epoch 2/150\n",
      "262591/262591 [==============================] - 862s 3ms/step - loss: 0.4175 - acc: 0.8592 - val_loss: 2.2057 - val_acc: 0.4740\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.42844 to 0.47405, saving model to weights_best_merged.hdf5\n",
      "Epoch 3/150\n",
      "262591/262591 [==============================] - 855s 3ms/step - loss: 0.3388 - acc: 0.8879 - val_loss: 1.5411 - val_acc: 0.5588\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.47405 to 0.55882, saving model to weights_best_merged.hdf5\n",
      "Epoch 4/150\n",
      "262591/262591 [==============================] - 855s 3ms/step - loss: 0.2836 - acc: 0.9074 - val_loss: 1.2365 - val_acc: 0.6075\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.55882 to 0.60747, saving model to weights_best_merged.hdf5\n",
      "Epoch 5/150\n",
      "262591/262591 [==============================] - 854s 3ms/step - loss: 0.2677 - acc: 0.9127 - val_loss: 1.2959 - val_acc: 0.6096\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.60747 to 0.60958, saving model to weights_best_merged.hdf5\n",
      "Epoch 6/150\n",
      "262591/262591 [==============================] - 854s 3ms/step - loss: 0.2367 - acc: 0.9240 - val_loss: 1.6301 - val_acc: 0.5593\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.60958\n",
      "Epoch 7/150\n",
      "262591/262591 [==============================] - 854s 3ms/step - loss: 0.2153 - acc: 0.9308 - val_loss: 1.4185 - val_acc: 0.6411\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.60958 to 0.64108, saving model to weights_best_merged.hdf5\n",
      "Epoch 8/150\n",
      "262591/262591 [==============================] - 853s 3ms/step - loss: 0.2012 - acc: 0.9355 - val_loss: 1.4950 - val_acc: 0.6363\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.64108\n",
      "Epoch 9/150\n",
      "262591/262591 [==============================] - 854s 3ms/step - loss: 0.1878 - acc: 0.9400 - val_loss: 1.3361 - val_acc: 0.6778\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.64108 to 0.67779, saving model to weights_best_merged.hdf5\n",
      "Epoch 10/150\n",
      "262591/262591 [==============================] - 856s 3ms/step - loss: 0.1859 - acc: 0.9407 - val_loss: 1.3264 - val_acc: 0.6639\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.67779\n",
      "Epoch 11/150\n",
      "262591/262591 [==============================] - 864s 3ms/step - loss: 0.1726 - acc: 0.9448 - val_loss: 1.3756 - val_acc: 0.6454\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.67779\n",
      "Epoch 12/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1608 - acc: 0.9497 - val_loss: 1.2772 - val_acc: 0.6822\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.67779 to 0.68222, saving model to weights_best_merged.hdf5\n",
      "Epoch 13/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1519 - acc: 0.9516 - val_loss: 1.6105 - val_acc: 0.6577\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.68222\n",
      "Epoch 14/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1455 - acc: 0.9539 - val_loss: 1.5887 - val_acc: 0.6422\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.68222\n",
      "Epoch 15/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1414 - acc: 0.9558 - val_loss: 1.6109 - val_acc: 0.6044\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.68222\n",
      "Epoch 16/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1346 - acc: 0.9572 - val_loss: 1.3541 - val_acc: 0.6679\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.68222\n",
      "Epoch 17/150\n",
      "262591/262591 [==============================] - 859s 3ms/step - loss: 0.1317 - acc: 0.9589 - val_loss: 1.1965 - val_acc: 0.7119\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.68222 to 0.71189, saving model to weights_best_merged.hdf5\n",
      "Epoch 18/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1253 - acc: 0.9608 - val_loss: 1.7752 - val_acc: 0.5908\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.71189\n",
      "Epoch 19/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1197 - acc: 0.9625 - val_loss: 1.6108 - val_acc: 0.6561\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.71189\n",
      "Epoch 20/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1151 - acc: 0.9641 - val_loss: 1.6013 - val_acc: 0.6652\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.71189\n",
      "Epoch 21/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1137 - acc: 0.9642 - val_loss: 1.6977 - val_acc: 0.6604\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.71189\n",
      "Epoch 22/150\n",
      "262591/262591 [==============================] - 856s 3ms/step - loss: 0.1076 - acc: 0.9666 - val_loss: 1.6750 - val_acc: 0.6763\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.71189\n",
      "Epoch 23/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1062 - acc: 0.9671 - val_loss: 1.4619 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.71189\n",
      "Epoch 24/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.1033 - acc: 0.9676 - val_loss: 1.3562 - val_acc: 0.6959\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.71189\n",
      "Epoch 25/150\n",
      "262591/262591 [==============================] - 860s 3ms/step - loss: 0.1011 - acc: 0.9685 - val_loss: 1.4552 - val_acc: 0.6851\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.71189\n",
      "Epoch 26/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0951 - acc: 0.9701 - val_loss: 1.8258 - val_acc: 0.6710\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.71189\n",
      "Epoch 27/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0929 - acc: 0.9710 - val_loss: 1.7919 - val_acc: 0.6521\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.71189\n",
      "Epoch 28/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0919 - acc: 0.9711 - val_loss: 2.0612 - val_acc: 0.6116\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.71189\n",
      "Epoch 29/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0879 - acc: 0.9728 - val_loss: 1.9066 - val_acc: 0.6379\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.71189\n",
      "Epoch 30/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0885 - acc: 0.9723 - val_loss: 1.9294 - val_acc: 0.6534\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.71189\n",
      "Epoch 31/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0833 - acc: 0.9741 - val_loss: 1.7383 - val_acc: 0.6730\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.71189\n",
      "Epoch 32/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0839 - acc: 0.9738 - val_loss: 2.1842 - val_acc: 0.6245\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.71189\n",
      "Epoch 33/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0855 - acc: 0.9732 - val_loss: 1.8937 - val_acc: 0.6513\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.71189\n",
      "Epoch 34/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0849 - acc: 0.9735 - val_loss: 1.5926 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.71189\n",
      "Epoch 35/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0754 - acc: 0.9765 - val_loss: 1.8824 - val_acc: 0.6554\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.71189\n",
      "Epoch 36/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0783 - acc: 0.9757 - val_loss: 1.9043 - val_acc: 0.6523\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.71189\n",
      "Epoch 37/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0752 - acc: 0.9767 - val_loss: 2.0441 - val_acc: 0.6518\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.71189\n",
      "Epoch 38/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0740 - acc: 0.9769 - val_loss: 1.8326 - val_acc: 0.6612\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.71189\n",
      "Epoch 39/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0722 - acc: 0.9778 - val_loss: 1.9835 - val_acc: 0.6246\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.71189\n",
      "Epoch 40/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0712 - acc: 0.9777 - val_loss: 2.1206 - val_acc: 0.6133\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.71189\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262591/262591 [==============================] - 858s 3ms/step - loss: 0.0684 - acc: 0.9788 - val_loss: 2.0807 - val_acc: 0.6342\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.71189\n",
      "Epoch 42/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0686 - acc: 0.9786 - val_loss: 2.0004 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.71189\n",
      "Epoch 43/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0666 - acc: 0.9792 - val_loss: 2.0201 - val_acc: 0.6386\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.71189\n",
      "Epoch 44/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0661 - acc: 0.9795 - val_loss: 2.1732 - val_acc: 0.6262\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.71189\n",
      "Epoch 45/150\n",
      "262591/262591 [==============================] - 858s 3ms/step - loss: 0.0646 - acc: 0.9800 - val_loss: 1.7782 - val_acc: 0.6684\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.71189\n",
      "Epoch 46/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0636 - acc: 0.9799 - val_loss: 1.7887 - val_acc: 0.6789\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.71189\n",
      "Epoch 47/150\n",
      "262591/262591 [==============================] - 857s 3ms/step - loss: 0.0621 - acc: 0.9806 - val_loss: 1.9173 - val_acc: 0.6520\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.71189\n",
      "Epoch 48/150\n",
      "262591/262591 [==============================] - 854s 3ms/step - loss: 0.0621 - acc: 0.9804 - val_loss: 2.0619 - val_acc: 0.6259\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.71189\n",
      "Epoch 49/150\n",
      "262591/262591 [==============================] - 853s 3ms/step - loss: 0.0609 - acc: 0.9811 - val_loss: 2.1166 - val_acc: 0.6485\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.71189\n",
      "Epoch 50/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0602 - acc: 0.9814 - val_loss: 1.9514 - val_acc: 0.6402\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.71189\n",
      "Epoch 51/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0598 - acc: 0.9817 - val_loss: 2.0127 - val_acc: 0.6354\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.71189\n",
      "Epoch 52/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0599 - acc: 0.9817 - val_loss: 1.9750 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.71189\n",
      "Epoch 53/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0590 - acc: 0.9816 - val_loss: 2.2157 - val_acc: 0.6102\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.71189\n",
      "Epoch 54/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0563 - acc: 0.9826 - val_loss: 2.1025 - val_acc: 0.6316\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.71189\n",
      "Epoch 55/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0553 - acc: 0.9826 - val_loss: 2.5736 - val_acc: 0.5905\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.71189\n",
      "Epoch 56/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0537 - acc: 0.9832 - val_loss: 2.3352 - val_acc: 0.6061\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.71189\n",
      "Epoch 57/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0556 - acc: 0.9827 - val_loss: 2.7268 - val_acc: 0.5719\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.71189\n",
      "Epoch 58/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0533 - acc: 0.9835 - val_loss: 2.0044 - val_acc: 0.6323\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.71189\n",
      "Epoch 59/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0523 - acc: 0.9836 - val_loss: 2.1100 - val_acc: 0.6348\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.71189\n",
      "Epoch 60/150\n",
      "262591/262591 [==============================] - 852s 3ms/step - loss: 0.0526 - acc: 0.9837 - val_loss: 2.2660 - val_acc: 0.6320\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.71189\n",
      "Epoch 61/150\n",
      "247200/262591 [===========================>..] - ETA: 48s - loss: 0.0507 - acc: 0.9842"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-b9da75f64b8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m              callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 200\n",
    "\n",
    "merged_model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best_merged.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "H = merged_model.fit([X_train[:,0:3], X_train[:,3:6], X_train[:,6:9]], y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            validation_data=([X_val[:,0:3], X_val[:,3:6], X_val[:,6:9]], y_val),\n",
    "             callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(262591, 10, 500, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Conv_1 (Conv2D)              (None, 11, 600, 64)       384       \n",
      "_________________________________________________________________\n",
      "batch_1 (BatchNormalization) (None, 11, 600, 64)       256       \n",
      "_________________________________________________________________\n",
      "drop_1 (Dropout)             (None, 11, 600, 64)       0         \n",
      "_________________________________________________________________\n",
      "Conv_2 (Conv2D)              (None, 11, 600, 128)      41088     \n",
      "_________________________________________________________________\n",
      "max_1 (MaxPooling2D)         (None, 11, 300, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_2 (BatchNormalization) (None, 11, 300, 128)      512       \n",
      "_________________________________________________________________\n",
      "drop_2 (Dropout)             (None, 11, 300, 128)      0         \n",
      "_________________________________________________________________\n",
      "Conv_3 (Conv2D)              (None, 11, 300, 256)      98560     \n",
      "_________________________________________________________________\n",
      "max_2 (MaxPooling2D)         (None, 11, 150, 256)      0         \n",
      "_________________________________________________________________\n",
      "batch_3 (BatchNormalization) (None, 11, 150, 256)      1024      \n",
      "_________________________________________________________________\n",
      "drop_3 (Dropout)             (None, 11, 150, 256)      0         \n",
      "_________________________________________________________________\n",
      "Conv_4 (Conv2D)              (None, 11, 150, 512)      393728    \n",
      "_________________________________________________________________\n",
      "max_3 (MaxPooling2D)         (None, 11, 75, 512)       0         \n",
      "_________________________________________________________________\n",
      "batch_4 (BatchNormalization) (None, 11, 75, 512)       2048      \n",
      "_________________________________________________________________\n",
      "drop_4 (Dropout)             (None, 11, 75, 512)       0         \n",
      "_________________________________________________________________\n",
      "Conv_5 (Conv2D)              (None, 11, 75, 256)       393472    \n",
      "_________________________________________________________________\n",
      "batch_5 (BatchNormalization) (None, 11, 75, 256)       1024      \n",
      "_________________________________________________________________\n",
      "drop_5 (Dropout)             (None, 11, 75, 256)       0         \n",
      "_________________________________________________________________\n",
      "Conv_6 (Conv2D)              (None, 11, 75, 128)       98432     \n",
      "_________________________________________________________________\n",
      "batch_6 (BatchNormalization) (None, 11, 75, 128)       512       \n",
      "_________________________________________________________________\n",
      "drop_6 (Dropout)             (None, 11, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "Conv_7 (Conv2D)              (None, 11, 75, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_7 (BatchNormalization) (None, 11, 75, 64)        256       \n",
      "_________________________________________________________________\n",
      "drop_7 (Dropout)             (None, 11, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "per_1 (Permute)              (None, 75, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "ren_1 (Reshape)              (None, 75, 704)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 64)                188928    \n",
      "_________________________________________________________________\n",
      "batch_8 (BatchNormalization) (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "drop_8 (Dropout)             (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               16640     \n",
      "_________________________________________________________________\n",
      "batch_9 (BatchNormalization) (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 1,313,992\n",
      "Trainable params: 1,310,536\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "p=0.4\n",
    "model = model_dcbl(p)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the model ... \n",
      "ConvLSTM\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 11, 600, 32)       192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 600, 32)       128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 11, 300, 32)       0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 300, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 300, 64)       6208      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 11, 300, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 150, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 150, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 150, 128)      73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 11, 150, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 11, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11, 75, 128)       0         \n",
      "_________________________________________________________________\n",
      "permute_1 (Permute)          (None, 75, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 75, 1408)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                369152    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 450,824\n",
      "Trainable params: 450,376\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('building the model ... ')\n",
    "model = Sequential()\n",
    "\n",
    "if network_type=='CNN' or network_type=='ConvLSTM':\n",
    "    model_conv(model, num_feat_map,p,b)\n",
    "    model_variant(model, num_feat_map, dim, network_type,p)\n",
    "if network_type=='LSTM':\n",
    "    model_LSTM(model,p)\n",
    "if network_type=='MLP': \n",
    "    model_MLP(model, num_hidden_mlp,p) \n",
    "       \n",
    "model_output(model)    \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 216923 samples, validate on 30989 samples\n",
      "Epoch 1/150\n",
      "216923/216923 [==============================] - 945s 4ms/step - loss: 0.9390 - acc: 0.6544 - val_loss: 2.0124 - val_acc: 0.3854\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.38536, saving model to weights_best_mag.hdf5\n",
      "Epoch 2/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.5711 - acc: 0.8086 - val_loss: 1.1170 - val_acc: 0.6497\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.38536 to 0.64971, saving model to weights_best_mag.hdf5\n",
      "Epoch 3/150\n",
      "216923/216923 [==============================] - 926s 4ms/step - loss: 0.4573 - acc: 0.8528 - val_loss: 1.0700 - val_acc: 0.6858\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.64971 to 0.68582, saving model to weights_best_mag.hdf5\n",
      "Epoch 4/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.3895 - acc: 0.8771 - val_loss: 0.9710 - val_acc: 0.7221\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.68582 to 0.72213, saving model to weights_best_mag.hdf5\n",
      "Epoch 5/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.3445 - acc: 0.8949 - val_loss: 1.0456 - val_acc: 0.7256\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.72213 to 0.72558, saving model to weights_best_mag.hdf5\n",
      "Epoch 6/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.3114 - acc: 0.9064 - val_loss: 0.9609 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.72558\n",
      "Epoch 7/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.2854 - acc: 0.9150 - val_loss: 0.8979 - val_acc: 0.7452\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.72558 to 0.74517, saving model to weights_best_mag.hdf5\n",
      "Epoch 8/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.2644 - acc: 0.9219 - val_loss: 0.9958 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.74517\n",
      "Epoch 9/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.2526 - acc: 0.9260 - val_loss: 0.8942 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.74517 to 0.74633, saving model to weights_best_mag.hdf5\n",
      "Epoch 10/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.2349 - acc: 0.9311 - val_loss: 1.0020 - val_acc: 0.7257\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.74633\n",
      "Epoch 11/150\n",
      "216923/216923 [==============================] - 927s 4ms/step - loss: 0.2224 - acc: 0.9353 - val_loss: 1.0320 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.74633\n",
      "Epoch 12/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.2111 - acc: 0.9380 - val_loss: 0.9561 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.74633\n",
      "Epoch 13/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.2029 - acc: 0.9406 - val_loss: 1.0731 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.74633\n",
      "Epoch 14/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1942 - acc: 0.9429 - val_loss: 1.1976 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.74633\n",
      "Epoch 15/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1842 - acc: 0.9465 - val_loss: 1.0450 - val_acc: 0.7364\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.74633\n",
      "Epoch 16/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1780 - acc: 0.9477 - val_loss: 1.1165 - val_acc: 0.7328\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.74633\n",
      "Epoch 17/150\n",
      "216923/216923 [==============================] - 930s 4ms/step - loss: 0.1719 - acc: 0.9501 - val_loss: 1.1314 - val_acc: 0.7353\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.74633\n",
      "Epoch 18/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1679 - acc: 0.9507 - val_loss: 1.1968 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.74633\n",
      "Epoch 19/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1613 - acc: 0.9527 - val_loss: 1.2897 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.74633\n",
      "Epoch 20/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1567 - acc: 0.9534 - val_loss: 1.2089 - val_acc: 0.7336\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.74633\n",
      "Epoch 21/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1493 - acc: 0.9553 - val_loss: 1.1255 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00021: val_acc improved from 0.74633 to 0.74836, saving model to weights_best_mag.hdf5\n",
      "Epoch 22/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1463 - acc: 0.9566 - val_loss: 1.4185 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.74836\n",
      "Epoch 23/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1447 - acc: 0.9567 - val_loss: 1.1472 - val_acc: 0.7344\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.74836\n",
      "Epoch 24/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1402 - acc: 0.9582 - val_loss: 1.2343 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.74836\n",
      "Epoch 25/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1350 - acc: 0.9598 - val_loss: 1.2504 - val_acc: 0.7161\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.74836\n",
      "Epoch 26/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1316 - acc: 0.9605 - val_loss: 1.3870 - val_acc: 0.7067\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.74836\n",
      "Epoch 27/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1285 - acc: 0.9610 - val_loss: 1.5735 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.74836\n",
      "Epoch 28/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.1251 - acc: 0.9619 - val_loss: 1.3511 - val_acc: 0.7178\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.74836\n",
      "Epoch 29/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.1230 - acc: 0.9625 - val_loss: 1.4589 - val_acc: 0.7032\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.74836\n",
      "Epoch 30/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1208 - acc: 0.9628 - val_loss: 1.4134 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.74836\n",
      "Epoch 31/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1166 - acc: 0.9645 - val_loss: 1.3162 - val_acc: 0.7288\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.74836\n",
      "Epoch 32/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1141 - acc: 0.9649 - val_loss: 1.4309 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.74836\n",
      "Epoch 33/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1115 - acc: 0.9653 - val_loss: 1.3023 - val_acc: 0.7174\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.74836\n",
      "Epoch 34/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1099 - acc: 0.9661 - val_loss: 1.5442 - val_acc: 0.7114\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.74836\n",
      "Epoch 35/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1074 - acc: 0.9666 - val_loss: 1.5159 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.74836\n",
      "Epoch 36/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1051 - acc: 0.9669 - val_loss: 1.4780 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.74836\n",
      "Epoch 37/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1033 - acc: 0.9674 - val_loss: 1.3480 - val_acc: 0.7282\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.74836\n",
      "Epoch 38/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.1026 - acc: 0.9677 - val_loss: 1.3324 - val_acc: 0.7278\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.74836\n",
      "Epoch 39/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.0990 - acc: 0.9689 - val_loss: 1.4345 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.74836\n",
      "Epoch 40/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.0973 - acc: 0.9691 - val_loss: 1.5415 - val_acc: 0.7112\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.74836\n",
      "Epoch 41/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.0954 - acc: 0.9702 - val_loss: 1.6289 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.74836\n",
      "Epoch 42/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.0952 - acc: 0.9699 - val_loss: 1.3732 - val_acc: 0.7191\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.74836\n",
      "Epoch 43/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.0937 - acc: 0.9700 - val_loss: 1.5156 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.74836\n",
      "Epoch 44/150\n",
      "216923/216923 [==============================] - 929s 4ms/step - loss: 0.0925 - acc: 0.9706 - val_loss: 1.4955 - val_acc: 0.7136\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.74836\n",
      "Epoch 45/150\n",
      "216923/216923 [==============================] - 928s 4ms/step - loss: 0.0889 - acc: 0.9713 - val_loss: 1.5992 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.74836\n",
      "Epoch 46/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0893 - acc: 0.9718 - val_loss: 1.4934 - val_acc: 0.7091\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.74836\n",
      "Epoch 47/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0868 - acc: 0.9724 - val_loss: 1.4696 - val_acc: 0.7132\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.74836\n",
      "Epoch 48/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0889 - acc: 0.9717 - val_loss: 1.3608 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.74836\n",
      "Epoch 49/150\n",
      "216923/216923 [==============================] - 923s 4ms/step - loss: 0.0823 - acc: 0.9739 - val_loss: 1.5270 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.74836\n",
      "Epoch 50/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0827 - acc: 0.9733 - val_loss: 1.4480 - val_acc: 0.7157\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.74836\n",
      "Epoch 51/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0799 - acc: 0.9738 - val_loss: 1.4577 - val_acc: 0.7091\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.74836\n",
      "Epoch 52/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0808 - acc: 0.9741 - val_loss: 1.5226 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.74836\n",
      "Epoch 53/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0814 - acc: 0.9733 - val_loss: 1.4560 - val_acc: 0.7090\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.74836\n",
      "Epoch 54/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0777 - acc: 0.9751 - val_loss: 1.5530 - val_acc: 0.7124\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.74836\n",
      "Epoch 55/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0776 - acc: 0.9749 - val_loss: 1.5673 - val_acc: 0.7144\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.74836\n",
      "Epoch 56/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0762 - acc: 0.9749 - val_loss: 1.6391 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.74836\n",
      "Epoch 57/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0740 - acc: 0.9760 - val_loss: 1.6897 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.74836\n",
      "Epoch 58/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0739 - acc: 0.9760 - val_loss: 1.4752 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.74836\n",
      "Epoch 59/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0727 - acc: 0.9765 - val_loss: 1.5643 - val_acc: 0.7135\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.74836\n",
      "Epoch 60/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0727 - acc: 0.9761 - val_loss: 1.5890 - val_acc: 0.7014\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.74836\n",
      "Epoch 61/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0716 - acc: 0.9767 - val_loss: 1.6000 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.74836\n",
      "Epoch 62/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0691 - acc: 0.9770 - val_loss: 1.8505 - val_acc: 0.6632\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.74836\n",
      "Epoch 63/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0691 - acc: 0.9775 - val_loss: 1.6045 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.74836\n",
      "Epoch 64/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0672 - acc: 0.9779 - val_loss: 1.6743 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.74836\n",
      "Epoch 65/150\n",
      "216923/216923 [==============================] - 924s 4ms/step - loss: 0.0686 - acc: 0.9775 - val_loss: 1.4899 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.74836\n",
      "Epoch 66/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0670 - acc: 0.9780 - val_loss: 1.5430 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.74836\n",
      "Epoch 67/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0660 - acc: 0.9782 - val_loss: 1.7453 - val_acc: 0.6899\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.74836\n",
      "Epoch 68/150\n",
      "216923/216923 [==============================] - 925s 4ms/step - loss: 0.0658 - acc: 0.9780 - val_loss: 1.5686 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.74836\n",
      "Epoch 69/150\n",
      " 41000/216923 [====>.........................] - ETA: 12:06 - loss: 0.0635 - acc: 0.9786"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-221836307ba8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m              callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 150\n",
    "batch_size = 200\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# checkpoint\n",
    "filepath=\"weights_best_mag.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "H = model.fit(X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            validation_data=(X_val, y_val),\n",
    "             callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = load_model('weights_best_mag.hdf5')\n",
    "model = load_model('weights_best_merged.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6979  634    2   87   56   83 1689  473]\n",
      " [ 133 7921    6   20    1    9    6   31]\n",
      " [   1   60 6262    3    0    0    0    0]\n",
      " [ 246  167    3 7904   74   46   24    5]\n",
      " [   3    0    0    2  585   78   25    2]\n",
      " [ 462   84    0  175  532 6195 1068  815]\n",
      " [2769  188    0    5 1178  996 8649 3777]\n",
      " [1804  291    1   71  421 1399 5435 5091]]\n",
      "the mean-f1 score: 0.67\n",
      "accuracy is: 0.66\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.argmax(model.predict([X_test[:,0:3], X_test[:,3:6], X_test[:,6:9]]), axis=1)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "#y_true = y_test\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true, y_pred, average=None)*100)*0.01\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnWuwHdV15//rnHt19RZIusgCcREEGTCpIJxrbEzKhXkYYjKQD04CiTOOTUrlGdvBKVcyplyu2JUPmdRMBdtTLo+V4Ng19pDxA08cygEzfgxhnJEjgbElhCIMYhBCL4z1ACFd3bPmw+lzdJ59unf3Pr0f/1/VrXse/Vj77N3/Xr322nuLqoIQQog/1Ko2gBBCSD4o3IQQ4hkUbkII8QwKNyGEeAaFmxBCPIPCTQghnkHhJoQQz6BwE0KIZ1C4CSHEMyZsHHT16tW6fv16G4cmhJAg2bZt22FVnc6yrRXhXr9+PbZu3Wrj0IQQEiQi8lzWbRkqIYQQz6BwE0KIZ1C4CSHEMyjchBDiGRRuQgjxjJHCLSKXiMiPO/6OisiHx2EcIYSQfkamA6rqLgAbAUBE6gBeAPBNy3YRQggZQt487usB/ExVM+cb+sbBY6/hvi3PY14Vv7nxXFw0vbQSO3btP4YHt+/Hb79pHdauWDRy+23P/Rz/tPswfmXdClx36ZqR239/10E8/tzLeGr/MZx71iJML5vCiVPz+Mg7Xg8RSd33+MnT+NIP92Dni0dx0eolmctkg31HXsPZiyexaLLe/EAEMFyO75nDr6SWp16r4dT8POojfp9xcPaSBThr8SQEgrn5BvYfeQ1z8w2jY/3SOUvxzKFX4OsyhrWa4PY3zeB1KxZWbcrYyCvctwO4b9AXIrIJwCYAmJmZKWhWdfzDEy/inv/1rwCAoyfm8IlbL6/Ejs8/8jPc/9gLmKgLPvD2i0duf8dfb8Gp080Ld89/vGXk9p/81g7seenVvs83rFmK2zael7rvo7sP4z89tKv9viod69SZlg2DPjM91rDv8x67bNL0Na9dpr+XK7TsXzBRw7+/dvR1EgqZhVtEFgC4FcDdg75X1c0ANgPA7Oysn7duAKcTr2Xp1ISxB1MG843mT5jVhpZoZ2VufnAVHTkxN3Lflm0AcMW6Ffj7D/5arnOXxY59R3DLZx4FADz7F82b1WUffxAn5ubxH26+FP/u2l/KfKyPfPUJfOOxvfiTmy4ZeKN8+ZVTuPLPHwYAfP73fxU3Xf66Ekpgxj88sQ8fuu/xvs9/9LHrcc6yfF7nuz73Q2x97mUsnZrA9k/eVJaJY2NuvoENH/tHNBreSo4RebJKfh3AY6p6wJYxLjCf3MIn6oJGhY+OrXZoq0EWKZvCjYukluIi1gy9x2GH7DxX2nnHwbDzV21XlXga5TEmj3DfgSFhkpBoCeVkvdblWVZlx7ylFlmkbK5cJPUUdU77LvWYw0Sx40qpV5xEO+z8LsTeyXjI1ARFZDGAGwHcb9ec6mlFJiZrggojJW1htWVDMY/bDdI97nwi1nqKGCb4nZ9X7dkO9bgNblatQ/kq+b7aXZRMMW5VfRXAKsu2OEFL0Op1qbSXvWWHLRuKPEy4kn1gw+POEoYwPXZZZLm5xIYbLXJ8cORkDw1V1KT52GkrTJHVDqBYSCONKsNAZZGmU3k1TBLfbdh+fsS4x2wIqQwKdw/zDUW9JqjVpFJxm7cc4y7S6emIw50eKjGNcfsQKhlio4ldrRuWrzGH1pgDV9rkuKBw9zCvipoI6lJtVkkrW89WVkmRG4IrWSWpoRLDGPdwUcx23nEwrGxV20XGB4W7B9Wm51ITQaPCzslWHNmW01/lTaks0oTK2OMeIorSFeM2OnRp1MrMKvHb4fbW7qJQuHvoCpVU6XFbD5WY79tlUoVhg7RT5w0bnIlxj95v1JQAthlmY8zZgK48BY4LCncP842kc7JmL0yR1Q7A0VCJI9dImodp6hVnEb+q86WHPWlUfUMh44PC3UNDmx43s0qG44hup4dKDGPcWcSv6lhymZ2jrSP5Kvqeml0YCncPTY9bIBJuVklRL96VPO5BcexRA2lGkaVsVWeVVH3jcBFHmuTYoHD30NCmINRrUmljaGmrDRuKdky6co2UOXIy13mr7pwssWjtkZOe3gt8fVIoCoW7h0ZDUU/SASudq8RiqKSwF9+5e4V3t0Gx5jydjIPIFCpxtHMyZlxxJsYFhbuH+WTkpIi9jI5MdlgNlRTb35Ue/DTP12Y4wTTVsCwYKiEU7h4aDW2HSkLNKil6M3Alnmgjq6ToecdBmcLdekLhrcAvKNw9tLNKatWOnGyd2sSGUR1socS4y8wqKeu844ChkgG44k2MCQp3D/Pa9KhqIhiySMyY7LA3rWvxrJKSDClIWjzaprhVrZt2Oif9vRl4bLoxFO4eGg2FSPPiqDJU0jq3mced/n3RDk9XYtxp2PSKq/a4qz6/i7jfIsuFwt1Da8h7verZAR3OKnHF407DaqiEWSWkYijcPTSS2QFrFc8O2Dq3DRt8EN6iMKskG76vgAP4bbspFO4eXOmcbKXsGYVKRnxfPFTSgaPen01trdrjrfr8LhKDM9IJhbuH1pD3mitD3m2ESooe04OrxKZXXHmoxMJV6/O9wOeOVVOyLhZ8loh8XUSeEpGdInK1bcOqYj4Z8l6ribW5sLPZ0crjzr9vLOmAadgU16qHvJdZNgkk0OBDh3mZZFosGMCnATyoqu8SkQUAFlu0qVJUFXUB6lLtYgNqMcYdgcPNrBISNCOFW0SWA3gbgD8AAFU9BeCUDWN++PThSr3chipeOn4KixfUURPBKyfn8ejuw+3vOmOLyxdNYMFEDQePnoRIcc9lxaJJHH1tri2KJ+earvYvTsy1behl1dIFWL5oEs8eeiX12LsPHMOBoyfb7/cdOTF020d3H8ZFq5e23ysUE7UaVBUzqxZjz+FXcfTEXNZiVYbNp+eqY8xlhgbOHMrfm4G/lpuTxeO+CMAhAH8rIlcA2AbgLlXtUgsR2QRgEwDMzMwYGXPnl7bixNy80b5lct2l52D5okkcPn4S7753S6W2PH3w+FAbagJML5vqEmWgO5Rx6nQDt3zmUZwaMJJn4WQNr811f/6dJw/gO08eKGz3OLn0dcvar9/2+tV4aMcBLF84mesYb75wJe5/7AVcfM7SodtcNL0Ezxx6BRMVe7xTE/2xmkvWLBuwZTz48BRYJlmEewLAGwF8SFW3iMinAXwUwMc7N1LVzQA2A8Ds7KzRz/jlP7yqMo/73n96Fg/u2I/f3HguPnHr5ZiaqOOWX1kLAPit//rPAIA/v+1yXLp2ObbueRl/+eBTXft/7f3mYf+v/svz+Nq2vVi+cAL3/sGbADS9iAtWLcGelwZ70w8/eQCbH3kGLx1Pf/g53Wjg1HwD737LDG7beF7784UTdfyX7+0eKNKtsrx0/CTe/+XH0o2v+Ip5/OM3YuFkvf3+nt/ZiBdePoHzV+aL5v327Pl42+unsXbFoqHbfOP9b8Wx105jouJFJxdO1vG//+RaHD5+ElMTzbKvXbGw0DF97t/z2XZTsgj3XgB7VbXl9n0dTeEunV+9YKWNw2bigSf2AQDWnrUIZy1eAAB40/puey5buxyz61fiyKv9oYLebfPQCoVM1mt9x5leNjVwn90HjgMY3FHYqaWt1zMrF/cde1iDb233YkpIxRXOXrKg6/3iBRPYYOB9ikiqaLfO1Xu+qrhg1RJcsGpJ1WY4Q2QO9+isElXdD+B5Ebkk+eh6AE9atYpkxpXVaAgh4yNrVsmHAHwlySh5BsB77ZlUDa0On7SnLlurhZgcr7XPKNlufT+o83RUh2ooqWJkOFnavevE2E4zCbeq/hjArGVbiAGDHO7YcloJie3BkyMne0j3fiXDNgbnNPAYsu7RCqUU8epJ+Hhd1z7bbgiFO2LomZMINS8IKNwJZ2ZJG96Us2xT6Nw5Dpu2bVmPjZnM8dpVI6EQmxNC4Q6ctOYcY6cO6caWMzJO/LXcHAp3gmSIX9saHWxyuLwXmtEw6RivCOIncTncFG6XsNEzHltvOzHD54iXz7abQuGOmNjigqSfCDUvCCjcCVmWcLI1WMHIY8jaOakjN085BS9r4gexuSAU7oihMBOOnPQTCnfCmY7HlHTA9iZlpwOWOwCnMwTSem1tAA6D6MQBYpuzh8JNCPF63UaPTTeGwp2QLcY9eptxkfVC05QY96jOSRfKSezCOvYTCneARPbUSEh0bZ7CndDupEkdgGNpkimTIe8Zt2tP6zrg4COndY3xGZR4R4ytlMIdIGN1PijuXhNK9UXmcFO4e6lkkimTaV1z7sIR7yQNnwU8xidDCnfgpKVJceQk4e3ZTyjcDlB2jnVsOa2ExNbkKdwJeVaKsfVkZmWSqeT/IJNHd06Wbg5xFJ/r2mPTjcm05qSI7AFwDMA8gNOqyvUnHSar/jNUQnwW7E5ia8tZV3kHgLer6mFrljhCFQNwbE4ApWfyAa2dgxAyXhgqISRi2vPv+HyT9th0U7IKtwL4johsE5FNNg2qmiwDcEpfAaf0zsmO161JpvKfIsoLgvhJbJ2TWUMl16jqPhE5B8DDIvKUqj7SuUEi6JsAYGZmpmQziQ1K8bJiu2ICxedYt8emG5PJ41bVfcn/gwC+CeCqAdtsVtVZVZ2dnp4u18oxkpbM79IAnMy0JpkacIqRk0zFeEVEBuvYT0YKt4gsEZFlrdcA3gFgu23DSAHoBBMSNFlCJWsAfDPxRCcA/HdVfdCqVRWQZdisyWRQ2c6d/7iZp3VtbT/Aqx+Zx53dHOIp7YnTKrajCDEOeR8p3Kr6DIArxmALKYmx5rRGeNEQ94httDDTAXPgUsqUO5aQEPDZa/XYdGMo3D1kGvJu34zS0EKdkz6VlJjAKvYTCncObDVyo8WCM+ZxExIDsTV5CncPWcIhPnmiaQNw2DlJXFpH1RSfbTeFwp0DWw2k7LlKYvM+CIntKZPCnRDstK4pMe5RePRgQYricV379ARcFhTuiIltKkzSj0uZUiQ7FO4eKpnW1eIKOGkDcEaegxc18YTYnBAKd8RQmEkLn1uCz7abQuHORTI8uOwh7yXv0+l7tL1vWzHu2HqFQiMQ1YutGVK4CSFed/B5bLoxFO6EPJNM2Tp3vkmmsm2X5omUEheM8aoJCNaen1C4jXC7uQ8Sa7ctJqQYkUVKKNx5sDYAp6J1xdg5SVr43RL8tt4ECrcBrkcHBoVAyp4PhYSBz7HtTtg5SYZiq5EbZZWEcb0RR/C5PflsuykUbgN8aidp2YAjp3X1qqTEBNawn1C4c2CtkZuEMdK+jOyxkZDYGj2FOyHP0ke2QiZWJpnC8MmzRk7rSncsGnx+uvLXcnMyC7eI1EXkcRF5wKZBhJDxwZuzn+TxuO8CsNOWIT5gbZIpk31SrrjuIe+t7Q3OkX8X4ik+C7gIs0oGIiLrANwC4G/smkPGSWwzqpF+PNbrqMnqcX8KwJ8CaFi0xXlsxQHL9oY7vQ/b0lznlU8cIDaPe2LUBiLyGwAOquo2Ebk2ZbtNADYBwMzMTGkGuoiPj5WDbjqjOyeHf3/DZefgwtVL8J63ri9qGiGF8Llj1ZSRwg3gGgC3isg7ASwEsFxEvqyq7+7cSFU3A9gMALOzs97d/yqdZMpgutjsk0yVUxULJmo4dfrMA9f7rrkQb714dSnHJtURysjJ2BgZKlHVu1V1naquB3A7gO/1inZsuH6HHzzkPf9xZMjrwR8Qn/FZwEXi669hHrcDVLWQb57G3ns+129eJBusRT/JEippo6o/APADK5Z4hOvOSVmdk66Xk5AWsXVO0uPOgb0Yt8k+453WtXdbinpY+FydPttuCoU7cM4MwDGZ1lU6Xvd8V8Qo4g6sSC+hcOfA2rSuJa8WHNlTIykBn5+gRCS6Nk/hTsg3yZQtG6wcFUBxx6p3f5+zEAjxHQp3gJSVu91Jr1BTt8MglOwgdk6SoUj7f7mN3eR4WfcoMskUiQe2D7+gcJNM9IVKKrGClA0F208o3Dmw1siNBuCkTOtqY5Kp3qwSXvBB4XPIhCMnSSZ8FK2iF+agKaoIIdVA4U7INMmUrWld2zbk32cUsXXakHwEc/uNrJ1TuA3w0uMuaDOzSsLG5/r02XZTKNw5sDbk3WhUowVDcpwvwmslSGIUvRCgcBvgekdOd+dkOQNwSNj43D4EHDlJUnAoqWTsNw+OnCTEHSjcBvikWWUNwOmLcRc7HHEE158eyWAo3HmwFuMud5/YclpJCfjkjfQgYmeaB5ehcCfkmmTKmg02j9lvda4VcHrf+3udkw5Yj35C4Q4QGzcALl1GXCYuf5vCnQtrA3AKLuSbRppXTfElLXxuCT7bbgqF2wDXHi+z2FPcZg7ACRHWo5+MFG4RWSgiPxKRJ0Rkh4h8chyGjZtMQ96trTkp+Y8vA18C6H5sLCtswgs8bHyuXxGJbmqHLKu8nwRwnaoeF5FJAI+KyD+q6v+1bJvDuNXKpdmtnr7NgM+YfUJca8skGyOFW5vpFseTt5PJX5RXvLUBOEYx7o6FfHu+s7ICTu97Xu/EIU43GvjMd3fj6Im5Su1YMjWBP77x9dbPk8XjhojUAWwDcDGAz6rqlgHbbAKwCQBmZmbKtNE5XBOtbDHuQROzZi8Is0rCxufaFAC79h/Dt3+6H1MTNUzUqivNqqVT7gi3qs4D2CgiZwH4poj8sqpu79lmM4DNADA7OxukR+7SMG/pinELhj0ElRbjZudkkIRSj42knX/2d9+IG96wplpjxkCurBJV/QWAHwC42Yo1nuBcW+8xaJBWO2czcQqXnJLccORkPyIynXjaEJFFAG4A8JRtw1zEXoy72GLBpnblGjnJpcuIwzRKmpPHF7KEStYC+FIS564B+KqqPmDXLLdxzTvpNWfgtK5FJ5nqe+/Wb0DMCKUWy2rnvpAlq+QnAK4cgy3OYy+P22CfDmNMRZTiS1r43BIEQKPReu1zSbLDkZMJLsTI7E4yVQwuXRYmwdVjaOUZAoXbANfaRv/F16/WZV+grv0GpBg+C3hz5GRcKz1RuHPg1CRTKUPeO0lzuDlykoTCmc7JOKSbwm2Aa20j0zwrBW86zCoJk1BiwrGtrUrhTsh0p3Zokqm0dMCurJKUIHeRkZPxXCJx4LOAC8pbos8XKNwGONfIs5jjmMnEDUIRupZ74ty1aQkKdw6spQOWHOPWIa+LwCHvgeNxfXZOjhlLu6RwG+Ba48gW4+6n0MjJzHsSYh9mlZChWBvyXnCv1BXfS5tkque9a3cvYkQotRhbfhSFOwDSOifb2xSc1pWEjc8tQXAmj9vrguSAwp0DW15m4Rj3GLzfvpGT1s9IxkEoT07tPO5IWiaFOwD6OyfL757kCjhh43N9Sse0rj6XIw8U7hy02kT5jaPgtK7VpaAT4gSRRUoo3C04ydQIuHQZcZh2HnckLjeF2wD3Gke3PYM7J8s8QzyPpLHg+42YoRIyFLcG4GRMBzSwh8RDKELXYKiEjMK1xpEpHbDwJFOulZqUic/VKyLRrYBD4U4Yxwx7w4/bsiH/PqP2szcAp5zjElIGjXY7j6NhUrgNcE20stxQXLOZuIHvse02nKukGxE5X0S+LyI7RWSHiNw1DsNcxF6M2yAdUAa/BrrzuMvKlumfjzuSKyQSfK5OQXzzcWdZ5f00gI+o6mMisgzANhF5WFWftGybs7jmpYxjVte+2QELHo+QMnEgm3esjPS4VfVFVX0seX0MwE4A59k2LCZMRLBTSHu9366FFAxt6jsfV8AJklY9uuaM5EGEedypiMh6AFcC2DLgu00islVEth46dKgc6xzFy7bho82EZKTBaV0HIyJLAXwDwIdV9Wjv96q6WVVnVXV2enq6TBudwa087mL7F8VnD42cIZRa5EIKAxCRSTRF+yuqer9dk0hexpIO2Ds7YCQXSCz4XJ/dq0F5XJAcZMkqEQD3Atipqn9l3yR3aS/qW/ZxCw9Hry4HnRCX8PkGlIcsHvc1AH4fwHUi8uPk752W7Ro7wU4yZWta11KOSqomBKGL0SkZmQ6oqo+C12k3jv0afXncNiaZonITDwjhRpQFjpzMgbXOSZP5uLvieilU/yBBHCa09LlYvG8KtwGuNY6+PO4Bal14AA7n4w4anwW86gyrKqBwJ2SbZMrWyVs25NmlYwBOynblraPArBLiPrG0Swq3Ac41jixLlzlnNHEB6fnvI10zZXpdkuxQuHNgbZV3k31SYtxdQ95Ly+PueV/OYQkhBlC4DXBNtDKFeUpfusy1X4EYEVg1xtIsKdw5sNUmCk/r2vOddr1mWgkZjdeCJ9n6e0KCwh0AY7noeoe8j+GUhOTF6xtQDijcOWhPgVly6yg8rWumIe/F4NJlYWJrGodxEqNLQeEOgP6Rk50r4Ng5Ryy998QvYnEoKNw5aHnaLkwylXefWBo0yUdo7SKw4gyFwh0A/SMnB78udI6RHxCf8TlLqHvkpL/lyAOF24Cy24bRXCVDXmfbo0mejBPOx018IJZmSeFOCHZaVwfKRdwlNKGLxaGgcBvgWsec6bSuRcrh1i9AiuJzfXLIe8RUGRs7k2aYf59R+9mKcccSSyR+EUuzpHCb4Fjj6Pcyyp/WlYSJidPgGjE6ERRuBzBrdh0DcAzndS0yHD6+S4UQd6BwB0AVIhqhkxMkocWEY2mXWVZ5/4KIHBSR7eMwyAdKbxxFB+D05nF3TuuaeNWDHidDu2hJEfxtC92Xgr/lyEMWj/uLAG62bAdxHA55Jz4QS6scKdyq+giAn4/BFm8o3+G2PwDHhWH6xD3C6Jwc/DpkGOMOgL487s7XHH9DIiKWJ8HShFtENonIVhHZeujQobIO6ySlT+tqFOPOt1MsngjJR2jNIpZ2Xppwq+pmVZ1V1dnp6emyDksyMJY1J7nKe9D4XJ3dc9PHAUMlBjiQVJJ7n7IfIWN5JCWeEUmzzJIOeB+AfwZwiYjsFZE77ZtFyoIhbpJKa455nwWva/1VnwuSnYlRG6jqHeMwxCdca+R983EPiI8Utrk3HdCx34AQIJ52yVCJAxRd5T0NW9O6RnJ9BA/r0U8o3AEweoopQtLxOcSQf1ER/6FwG1B6R59JOmBGG2yJeCxDi4lfxNIuKdwBUEVbjePyCJ8QdK5r5GR1ZowVCrcB5a85WcyGXu97UB53CBcoIaOIpZ1TuEkm+lfAqcQMQlLxOVafBwq3A5SdqjdogYTy4/JxXCChE4LQCeKLlVC4g4c5JiQeYvEnKNwGlN84iuVxZ5rWNZIGTfIRQrtg5yTxkr6Lz8YkU7FcEcRrYgnhUbgNcCKPm9O6EtJHLM2cwh0gOuQ1Ib2EIHRcAYdkwrXGkeUJoOhTQgjZB4SEAoXbAWzOx82ly0garjkhJnQvpBBAgTJA4Q6AvjUnKdYkUkK4EWWBwm1A+SumW5zWNYlyx9KgCYkBCncAUJSJKSGkz7FzkmSi9FXejfYZvlfnkPf2JFMG5yDENxjjJt4wjsYaiydD/CaWdppJuEXkZhHZJSJPi8hHbRvlOuXHuIvtk6VzMpYGTeImlmaeZZX3OoDPAvh1AG8AcIeIvMG2YaQcmGBCYiKEmH0WsnjcVwF4WlWfUdVTAP4OwG12zXKb8hdSMMgqGcMeJHxC0LlOsQ6gOJmYyLDNeQCe73i/F8Cb7ZhTHZP1ZpVP1KsL+69YNGm0X63n6rv7/p9i8YI6AODYa6eH7jc12V/Wem1w0180WTeyjZBxEsKNKAtZhHvQT9H3BC4imwBsAoCZmZmCZo2fD7z9YpyeV/zem/tt/9YHr8FP9h5pvxcR/NH1G3D0xBzecO5yrF+1pNC5N6xZijuuOh+3XnFe5n1WL53Ce69ZjyMn5vC+ay7EqqUL8OzhV7DvFydwxfkrurY9e/ECXLBqcd8xPvFvLseu/cdww2Vr8NCO/Xj51Tl85Q+778n3/M4V+OtHnsWnbt+IL/6fPdiwZhkOHH3NrKDEOW68bA2eevEYfmt2XdWmGPO7V81g6VQdF08vjSZUIjpimJ2IXA3gE6p6U/L+bgBQ1b8Yts/s7Kxu3bq1TDsJISRoRGSbqs5m2TZLXOBfAGwQkQtFZAGA2wF8q4iBhBBCzBkZKlHV0yLyQQAPAagD+IKq7rBuGSGEkIFkiXFDVb8N4NuWbSGEEJIBjpwkhBDPoHATQohnULgJIcQzKNyEEOIZFG5CCPGMkQNwjA4qcgjAc4a7rwZwuERzfIBljgOWOXyKlPcCVZ3OsqEV4S6CiGzNOnooFFjmOGCZw2dc5WWohBBCPIPCTQghnuGicG+u2oAKYJnjgGUOn7GU17kYNyGEkHRc9LgJIYSk4Ixwh7ogsYicLyLfF5GdIrJDRO5KPl8pIg+LyO7k/9nJ5yIin0l+h5+IyBurLYE5IlIXkcdF5IHk/YUisiUp8/9IpgmGiEwl759Ovl9fpd2miMhZIvJ1EXkqqe+rQ69nEfnjpF1vF5H7RGRhaPUsIl8QkYMisr3js9z1KiLvSbbfLSLvKWKTE8Id+ILEpwF8RFUvA/AWAB9IyvZRAN9V1Q0Avpu8B5q/wYbkbxOAz43f5NK4C8DOjvd/CeCepMwvA7gz+fxOAC+r6sUA7km285FPA3hQVS8FcAWaZQ+2nkXkPAB/BGBWVX8ZzWmfb0d49fxFADf3fJarXkVkJYA/Q3PZx6sA/FlL7I1Q1cr/AFwN4KGO93cDuLtquyyV9e8B3AhgF4C1yWdrAexKXn8ewB0d27e38+kPwLqkQV8H4AE0l8A7DGCit87RnOv96uT1RLKdVF2GnOVdDuDZXrtDrmecWY92ZVJvDwC4KcR6BrAewHbTegVwB4DPd3zetV3ePyc8bgxekDj7AoyekDwaXglgC4A1qvoiACT/z0k2C+W3+BSAPwXQSN6vAvALVW2tXtxZrnaZk++PJNv7xEUADgH42yQ89DcisgQB17OqvgDgPwP4fwBeRLPetiHsem6Rt15LrW9XhDvTgsQ+IyJLAXwDwIdV9WjapgM+8+q3EJHfAHBQVbd1fjxgU83wnS9MAHgjgM+p6pUAXsGZx+dBeF/m5FH/NgAXAjgXwBLN9jANAAABx0lEQVQ0QwW9hFTPoxhWxlLL7opw7wVwfsf7dQD2VWRL6YjIJJqi/RVVvT/5+ICIrE2+XwvgYPJ5CL/FNQBuFZE9AP4OzXDJpwCcJSKtVZc6y9Uuc/L9CgA/H6fBJbAXwF5V3ZK8/zqaQh5yPd8A4FlVPaSqcwDuB/BWhF3PLfLWa6n17YpwB7sgsYgIgHsB7FTVv+r46lsAWj3L70Ez9t36/N8mvdNvAXCk9UjmC6p6t6quU9X1aNbl91T19wB8H8C7ks16y9z6Ld6VbO+VJ6aq+wE8LyKXJB9dD+BJBFzPaIZI3iIii5N23ipzsPXcQd56fQjAO0Tk7ORJ5R3JZ2ZUHfTvCNa/E8C/AvgZgI9VbU+J5fo1NB+JfgLgx8nfO9GM7X0XwO7k/8pke0Ezw+ZnAH6KZo995eUoUP5rATyQvL4IwI8APA3gawCmks8XJu+fTr6/qGq7Dcu6EcDWpK7/J4CzQ69nAJ8E8BSA7QD+G4Cp0OoZwH1oxvDn0PSc7zSpVwDvS8r+NID3FrGJIycJIcQzXAmVEEIIyQiFmxBCPIPCTQghnkHhJoQQz6BwE0KIZ1C4CSHEMyjchBDiGRRuQgjxjP8PMBhhgXoobFEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_pred[:1000])\n",
    "#plt.plot(y_true[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3263"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(len(y_pred)/23)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 23\n",
    "y_pred2 = np.zeros((int(len(y_pred)/k)+1))\n",
    "y_true2 = np.zeros((int(len(y_pred)/k)+1))\n",
    "ind = 0\n",
    "for i in range (0,len(y_pred), k):\n",
    "    (values,counts) = np.unique(y_pred[i:i+k],return_counts=True)\n",
    "    c = np.argmax(counts)\n",
    "    y_pred2[ind] = values[c]\n",
    "    (values,counts) = np.unique(y_true[i:i+k],return_counts=True)\n",
    "    c = np.argmax(counts)\n",
    "    y_true2[ind] = values[c]\n",
    "    ind = ind+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_pred2[:100])\n",
    "#plt.plot(y_true[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[317  27   0   0   0   1  70  21]\n",
      " [  2 350   0   0   0   0   0   1]\n",
      " [  0   1 275   0   0   0   0   0]\n",
      " [  8   2   0 359   1   0   0   0]\n",
      " [  0   0   0   0  27   3   0   0]\n",
      " [ 12   4   0   5  19 297  45  24]\n",
      " [127   3   0   0  48  36 399 152]\n",
      " [ 74  10   0   1  10  52 249 231]]\n",
      "the mean-f1 score: 0.71\n",
      "accuracy is: 0.69\n"
     ]
    }
   ],
   "source": [
    "cf_matrix = confusion_matrix(y_true2, y_pred2)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true2, y_pred2, average=None)*100)*0.01\n",
    "accuracy = accuracy_score(y_true2, y_pred2)\n",
    "\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5698,)\n",
      "(5698, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2.shape)\n",
    "y_pred2 = np.int8(y_pred2) + 1\n",
    "y_pred2 = y_pred2.repeat(6000).reshape(-1,6000)\n",
    "print(y_pred2.shape)\n",
    "\n",
    "# y_true = np.int8(data['arr_20'] )\n",
    "# y_true = y_true[-2397:,:] #test = -2397:, val = 1739\n",
    "# #y_true = y_true[:1739,:]\n",
    "# print(y_true.shape)\n",
    "\n",
    "out_path='/home/sandeep/storage/HASCA-Workshop/Vikranth/Predictions/Final_60/'\n",
    "\n",
    "# data file with all the 16310 frames: 'Data_16310.npz'\n",
    "# data file with only 1000 frames: 'Data_1000.npz'\n",
    "\n",
    "out_file='shl_all_92'\n",
    "np.save(out_path + out_file, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14382000,)\n",
      "(14382000,)\n",
      "[[2030415   17765    2528    6626   25409    8586   41325    4904]\n",
      " [  31460 1745173    1555    7421    1076    1361    9704    8796]\n",
      " [      0    4898  584178       0    1324       0       0       0]\n",
      " [  37083   17419    2538 1818924     851    1531    3411       0]\n",
      " [  12000    4019    1037    3971 2190592    6000   24000       0]\n",
      " [   9390    7878    2164    2710   12748 1709835   19057       0]\n",
      " [ 117762    2383       0    2348       0   12687 1926870   52273]\n",
      " [ 107890    6465       0       0    6000       0  381633 1344027]]\n",
      "the mean-f1 score: 0.933424\n",
      "accuracy is: 0.928245\n"
     ]
    }
   ],
   "source": [
    "# #y_true = y_true.reshape(-1)\n",
    "# y_pred2 = y_pred2.reshape(-1)\n",
    "# #print(y_true.shape)\n",
    "# print(y_pred2.shape)\n",
    "# cf_matrix = confusion_matrix(y_true, y_pred2)\n",
    "# print(cf_matrix)\n",
    "# class_wise_f1 = f1_score(y_true, y_pred2, average=None)\n",
    "# accuracy = accuracy_score(y_true, y_pred2)\n",
    "\n",
    "# print('the mean-f1 score: {:.6f}'.format(np.mean(class_wise_f1)))\n",
    "# print('accuracy is: {:.6f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.zeros((int(len(y_pred)/10)*2))\n",
    "#y_true2 = np.zeros((int(len(y_pred)/10)*2))\n",
    "ind = 0\n",
    "for i in range (0,len(y_pred), 10):\n",
    "    (values,counts) = np.unique(y_pred[i:i+5],return_counts=True)\n",
    "    c = np.argmax(counts)\n",
    "    y_pred2[ind] = values[c]\n",
    "#     (values,counts) = np.unique(y_true[i:i+5],return_counts=True)\n",
    "#     c = np.argmax(counts) \n",
    "#     y_true2[ind] = values[c]\n",
    "    (values,counts) = np.unique(y_pred[i+5:i+10],return_counts=True)\n",
    "    c = np.argmax(counts)\n",
    "    y_pred2[ind+1] = values[c]\n",
    "#     (values,counts) = np.unique(y_true[i+5:i+10],return_counts=True)\n",
    "#     c = np.argmax(counts)\n",
    "#     y_true2[ind+1] = values[c]\n",
    "    ind = ind+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdbfe980240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_pred2[:200])\n",
    "#plt.plot(y_true[:100])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11396,)\n",
      "(5698, 6000)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2.shape)\n",
    "y_pred2 = np.int8(y_pred2) + 1\n",
    "y_pred2 = y_pred2.repeat(3000).reshape(-1,6000)\n",
    "print(y_pred2.shape)\n",
    "\n",
    "# y_true = np.int8(data['arr_20'] )\n",
    "# y_true = y_true[-2397:,:] #test = -2397:, val = 1739\n",
    "# #y_true = y_true[:1739,:]\n",
    "# print(y_true.shape)\n",
    "\n",
    "out_path='/home/sandeep/storage/HASCA-Workshop/Vikranth/Predictions/Final_30/'\n",
    "\n",
    "# data file with all the 16310 frames: 'Data_16310.npz'\n",
    "# data file with only 1000 frames: 'Data_1000.npz'\n",
    "\n",
    "out_file='shl_all_92'\n",
    "np.save(out_path + out_file, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14382000,)\n",
      "(14382000,)\n",
      "[[2033822   14496       0    5020   19727   11961   45335    7197]\n",
      " [  38138 1739489    4559    3138    1540    9202    6209    4271]\n",
      " [    472    7902  580728     462       0     836       0       0]\n",
      " [  33508    4136       0 1834772    1187    4531     623    3000]\n",
      " [  18000    3074    2713    1307 2189525    6000   18000    3000]\n",
      " [  19484    4057       0    2710   21748 1700783   15000       0]\n",
      " [ 108509    2615       0    3591    7273   24687 1895648   72000]\n",
      " [ 142067    6231       0    3000    6000   42000  371185 1275532]]\n",
      "the mean-f1 score: 0.926050\n",
      "accuracy is: 0.921311\n"
     ]
    }
   ],
   "source": [
    "y_true = y_true.reshape(-1)\n",
    "y_pred2 = y_pred2.reshape(-1)\n",
    "print(y_true.shape)\n",
    "print(y_pred2.shape)\n",
    "cf_matrix = confusion_matrix(y_true, y_pred2)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = f1_score(y_true, y_pred2, average=None)\n",
    "accuracy = accuracy_score(y_true, y_pred2)\n",
    "\n",
    "print('the mean-f1 score: {:.6f}'.format(np.mean(class_wise_f1)))\n",
    "print('accuracy is: {:.6f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Conv_lstm_mag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Conv_Lstm89:\n",
    "[[278   4   0   6   1   2  26  27]\n",
    " [  4 283   0   1   1   0   1   2]\n",
    " [  0   2  94   0   1   0   0   0]\n",
    " [  6   5   0 285   0   0   0   2]\n",
    " [  0   1   1   2 358   1   0   1]\n",
    " [  1   2   1   2  10 258   1   7]\n",
    " [  9   3   0   2   4   5 278  37]\n",
    " [  6   3   0   0   4  14  48 220]]\n",
    "the mean-f1 score: 0.90\n",
    "accuracy is: 0.89\n",
    "\n",
    "weights.best.hdf5:\n",
    "[[311   3   0   6   0   2   8  14]\n",
    " [  4 282   0   1   1   0   1   3]\n",
    " [  0   2  94   0   1   0   0   0]\n",
    " [  8   5   0 284   0   0   0   1]\n",
    " [  1   1   1   2 355   3   0   1]\n",
    " [  1   2   1   2   1 267   1   7]\n",
    " [ 24   2   0   2   2   8 247  53]\n",
    " [ 20   3   0   0   1  19  22 230]]\n",
    "the mean-f1 score: 0.90\n",
    "accuracy is: 0.90\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
